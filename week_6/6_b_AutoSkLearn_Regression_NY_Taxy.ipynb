{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananassio/Data-Science_lab/blob/main/week_6/6_b_AutoSkLearn_Regression_NY_Taxy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiEhciaogQ0T"
      },
      "source": [
        "# Block 6 Exercise 2: finding the best parameters for predicting the fare of taxi rides\n",
        "We return to our Random Forest Regression and want to automatically optimize all free parameters ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wfUoebPUgQ0Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import folium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A9zOS14gQ0c",
        "outputId": "9899449f-a6b5-4494-e825-b1f6b83cd0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATA'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 96 (delta 1), reused 9 (delta 1), pack-reused 87\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "Checking out files: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "#in colab, we need to clone the data from the repo\n",
        "!git clone https://github.com/keuperj/DATA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tmy6l5uMgQ0f"
      },
      "outputs": [],
      "source": [
        "# we load the data we have saved after wrangling and pre-processing in block I\n",
        "X=pd.read_csv('DATA/train_cleaned.csv')\n",
        "drop_columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','key','pickup_datetime','pickup_date','pickup_latitude_round3','pickup_longitude_round3','dropoff_latitude_round3','dropoff_longitude_round3']\n",
        "X=X.drop(drop_columns,axis=1)\n",
        "X=pd.get_dummies(X)# one hot coding\n",
        "#generate labels\n",
        "y=X['fare_amount']\n",
        "X=X.drop(['fare_amount'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDJC4f0kgQ0h"
      },
      "source": [
        "### Scikit Optimize\n",
        "Scikit Optimize (https://scikit-optimize.github.io/stable/index.html) is a AutoML toolbox wrapped around Scikit-Learn. It allows us to use state-of-the-art automatic hyper-parameter optimization on top of our learning algorithms.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mx7qJFBgQ0h",
        "outputId": "9f83c071-3bce-4dcf-f94e-bef655b15352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# install \n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE6vQyP3gQ0i"
      },
      "source": [
        "### E 2.1 Bayesian Optimization of a Random Forest Regression Model\n",
        "use Bayesian Optimization with Cross-Validation (https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV) to find the best regression model. Compare\n",
        "* linear regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) \n",
        "* Random Forest regression (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
        "* and SVM regression (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)\n",
        "\n",
        "NOTES: this can become quite compute intensive! Hence,\n",
        "* use a smaller subset of the training data to run the experiments \n",
        "* think about the range of your parameters (e.g. larger number of trees in RF or high C-values in SMV will make models expensive)\n",
        "* optimize only the following parameters per model type:\n",
        "    * linear: no parameters to optimize\n",
        "    * RF: #trees and depth\n",
        "    * SVM: C and gamma (use RBF kernel)\n",
        "* parallelize -> n_jobs\n",
        "* use CoLab to rum the job for up to 12h \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "hs78Wi59SG5S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uZZYvHMtgQ0l"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70) #split 85% train 15% test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer"
      ],
      "metadata": {
        "id": "FptPwvSUSQEf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "# Linear Regression\n",
        "%%time\n",
        "LR = LinearRegression(n_jobs=-1)\n",
        "LR.fit(X_train,y_train)\n",
        "print(LR.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yBKGGz4SFjy",
        "outputId": "dc584e38-b9ba-4ec1-fec2-9f04142613a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7353412380308091\n",
            "CPU times: user 237 ms, sys: 81.9 ms, total: 319 ms\n",
            "Wall time: 227 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "# Randomforest Regression\n",
        "%%time\n",
        "RFR =RandomForestRegressor(n_jobs=-1, n_estimators=100)\n",
        "RFR.fit(X_train,y_train)\n",
        "print(RFR.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9biTsL5ZVLNd",
        "outputId": "bcd109e3-9dfa-44ba-e376-ae773e2390ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8081623700903032\n",
            "CPU times: user 3min 55s, sys: 1.12 s, total: 3min 56s\n",
            "Wall time: 2min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "# SVM Regression\n",
        "SVM = make_pipeline(StandardScaler(), SVR(max_iter=50))\n",
        "SVM.fit(X_train, y_train)\n",
        "print(SVM.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ch5VFTjYgK9",
        "outputId": "71276799-e682-462b-9e77-0e15f8d1753e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-15.692103780352493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "# optimazation Randomforest Regression\n",
        "serches_RFR = {'n_estimators':[100,250,500],\n",
        "               'max_depth': [1,5,10]\n",
        "               }"
      ],
      "metadata": {
        "id": "iPhtlMsstaYk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "opt_RFR = BayesSearchCV(RFR,search_spaces=serches_RFR,n_iter=32,random_state=0,n_jobs=-1)\n",
        "# executes bayesian optimization\n",
        "opt_RFR.fit(X_train, y_train)\n",
        "\n",
        "# model can be saved, used for predictions or scoring\n",
        "print(opt_RFR.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL-W66NJtagP",
        "outputId": "3f26a7f1-4a9b-4497-e23d-672783326475"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8090575311325563\n",
            "CPU times: user 11min 7s, sys: 23.8 s, total: 11min 31s\n",
            "Wall time: 4h 28min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "# optimazation SVM Regression\n",
        "serches_SVM = {'svr__C':Real(1e-5, 1e+6, prior='log-uniform'),\n",
        "               'svr__gamma': Real(1e-5, 1e+3, prior='log-uniform')\n",
        "               }"
      ],
      "metadata": {
        "id": "w3ZeyBW7n59f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM.get_params().keys()"
      ],
      "metadata": {
        "id": "w0kvG4BLvwUO",
        "outputId": "491e4c53-24dc-44cc-af39-25aafebb59f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'svr', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'svr__C', 'svr__cache_size', 'svr__coef0', 'svr__degree', 'svr__epsilon', 'svr__gamma', 'svr__kernel', 'svr__max_iter', 'svr__shrinking', 'svr__tol', 'svr__verbose'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "opt_SVM = BayesSearchCV(SVM,search_spaces=serches_SVM,n_iter=32,random_state=0,n_jobs=-1)\n",
        "# executes bayesian optimization\n",
        "opt_SVM.fit(X_train, y_train)\n",
        "\n",
        "# model can be saved, used for predictions or scoring\n",
        "print(opt_SVM.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "bvF24lDpk69z",
        "outputId": "ec190a6b-0055-4b57-e087-d8bdec4967c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-9.30610787454622\n",
            "CPU times: user 41.6 s, sys: 20.3 s, total: 1min 1s\n",
            "Wall time: 3min 31s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "6_b_AutoSkLearn_Regression_NY_Taxy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}